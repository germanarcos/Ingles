El experimento (prueba) de aguante del SSD: Están todos muertos
Nunca pensé todo este trabajo de periodismo sobre tecnología me convertiría en un asesino en masa. Y aquí estoy, con la sangre de seis SSDS en mis manos, y no es ni si quiera la mitad. No fueron crimes pasionales ni fruto de la rabia, ni tampoco fueron accidentales. Hace más de 18 meses, prometí llevar los seis dispositivos hacia sus amargos finales. No lo hice en nombre de dios ni de la patria ni si quiera en defensa propia. Lo hice solo para verlos morir.
Técnicamente, también soy un torturador, o al menos un interrogador mejorado. En vez de ofrecerles una rapida e indolora muerte, exprimí lentamente toda gota de vida con un flujo imparable de escritura mucho más exigente que a lo que el SSD se enfrentaría en un típico PC. Para hacer las cosas peor, he explotado (aprovechado) su sufrimiento haciendo una crónica del proceso online.
Hoy, esta historia se acerca a su capítulo final en el experimento de aguante de SSD. Los dos últimos supervivientes conocieron su final en el camino a 2.5PB, uniéndose a cuatro compañeros (camaradas) caídos que murieron antes. Es hora de honrar a los muertos y mostrar lo que hemos aprendido de esta carnicería.

Experimento con intención de matar.
Antes de que lleguemos al final, tenemos que empezar por el principio. Si no eres familiar con el experimento, este artículo introductorio proporciona un análisis de nuestros sistemas de test y metodos. Nosotros solo damos un rápido análisis de los detalles aqui.
Nuestra marcha de la muerte de SSD fue diseñada para comprobar el límite de escritura inherente(propio) de las memorias NAND flash. Esta variedad de almacenamiento no volátil almacena datos atrapando electrones dentro de celdas de memoria nanoscale???. Un proceso llamado tunneling se usa para mover electrones dentro y fuera de las celdas, pero el tráfico de ida y vuelta erosiona la estructura física de la celda, llevandola a brechas(desgastes) que lo pueden hacer inutil.
Los electrones tambien se quedan atrapados en la pared de la celda, donde sus cargas negativas complican el proceso de leer y escribir datos. Esta acumulación de electrones descarriados llega a comprometer la capacidad de la celda de retener datos fiablemente -y de acceder a ella rapidamente. Los TLC NAND de tres bits diferencian entre mas valores dentro del posible rango de voltaje de la celda, haciendolo mas sensible al aumento de electrones que las MLC NAND de dos bits.

Incluso con algoritmos que nivelan el desgaste de igual forma por toda la memoria, todas las celdas acabarán callendo o convirtiendose inadecuadas para el deber. Cuando esto ocurre, son retiradas y reemplazadas con la memoria flash localizada en el area de sobreprovisionamiento (OP) del SSD. Esta NAND de repuesto asegura que la capacidad del dispositivo accesible para el usuario no es afectada por la guerra de desgaste devastando sus celdas.
Las bajas finalmente superaran la capacidad del dispositivo para compensar, dejando preguntas sin responder. ¿Cuántas escrituras serán necesarias? ¿Qué pasa con tus datos al final? ¿Los SSD pierden fiabilidad o rendimiento conforme se acumulan las escrituras?
Este experimento buscaba encontrar las respuestas escribiendo un flujo constante de datos a Corsair's Neutron GTX 240GB, Intel's 335 Series 240GB, Kingston's HyperX 3K 240GB, Samsung's 840 Series 250GB, and Samsung's 840 Pro 256GB.

La primera lección llego pronto. Todos los dispositivos sobrepasaron las especifiaciones oficiales de aguante, escribiendo cientos de terabytes sin ningún problema. Cumplir con la tolerancia de escritura garantizada por el creador no debería ser motivo de celebración, pero la escala hace este logro importante. La mayoría de usuarios, yo mismo incluido, no escriben más de unos pocos de terabytes por año. Incluso 100TB es mucha más resistencia que la que necesita el tipico consumidor.
A los 200TB de escrituras se aprecio una clara evidencia de desgaste de la memoria flash, cuando el samsung 840 series empezo apuntando sectores relocalizados. Siendo el unico candidato TLC en el experimento, este dispositivo se esperaba que fuera el primero en mostrar errores. No encontro problemas serioes hasta los 300TB, cuando fallo un check de hash durante la preparación para un test de retención de datos sin energía. El dispositivo consiguió pasar el test y continuar escribiendo, pero registró una erupción de errores incorregibles. Pueden comprometer la integridad de datos y la estabilidad del sistema, así que recomendamos retirar los dispositivos fuera de servicio en el momento que aparecen.
Después de recibir una "marca negra" en su registro permanente, el 840 navegó suavemente hasta los 800TB. Pero sufrió otra avalancha de errores incorregibles en el camino hacia los 900TB, y murió sin aviso antes de alcanzar el PB. A pesar de que había retirado miles de bloqueus de memoria flash hasta ese punto, los atributos SMART sugerían que quedaban bastantes reservas. El dispositivo pudo haber sido derribado por una repentina aparición de fallos flash demasiado severos como para contrarrestarlo. En cualquier caso, el golpe final fue fatal, nuestros intentos por recuperar datos del dispositivo fallaron.
Pocos esperaban que un SSD TLC durara tanto, y aun menos habrían apostado que durara más que dos dispositivos basados en MLC. Intel 335 Series fallaron mucho antes, aunque, para ser justo,  el mismo pulso el gatillo. El indicador del desgaste del dispositivo se agotó poco despues de 700TB, señalando que la tolerancia de escritura NAND había sido sobrepasada. Intel no confía en el dispositivo a ese punto, así que está diseñado para cambiar en un modo de solo lectura, y después inutilizarse a si mismo cuando se quita la energía. A pesar de sufrir solo un sector relocalizado, nuestro ejemplo cumplió el guión con deber. Los datos eran accesibles hasta que un reinicio forzó al dispositivo a tragar su pastilla de cianuro virtual.
La parca vino por Kingston HyperX 3k después. Como con las Series 335, el indicador de vida de los datos SMART avisó sobre la muerte del dispositivo y mostró mensajes avisando de que el final se acercaba. La memoria aguantó bien a través de los 600TB pero sufrió muchos fallos y sectores relocalizados hasta los 728TB, después de lo cual se negó a escribir. Por lo menos los datos seguían siendo accesibles al final. Aunque no respondió después de un reinicio. Kingston nos dice que el dispositivo no arrancará si su reserva NAND ha sido agotada.
El siguiente error ocurrio despues de que las series 840 mordieran el polvo. Corsair's Neutron GTX no tenía practicamente ningún fallo hasta los 1.1PB, pero tuvo miles de sectores relocalizados y produjo numerosos mensajes de aviso durante los siguientes 100TB. El dispositivo todavía era funcional después de 1.2PB de escrituras, y sus atributos SMART sugerian que quedaba memoria flash en reserva. Aun así, no consiguió arrancar después de un reboot. Como con los demás cadáveres, el dispositivo ni si quiera fue detectado, negando cualquier posibilidad de recuperar facilmente los datos.
Y después llego la calma. Los dos SSDs restantes llegaron pasados los 2PB antes de conocer su final. En la siguiente pagina, examinaremos sus ultimos momentos en detalle